{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "          text\nclass         \nearn      3923\nacq       2292\ncrude      374\ntrade      326\nmoney-fx   293\ninterest   271\nship       144\ngrain       51",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>class</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>earn</th>\n      <td>3923</td>\n    </tr>\n    <tr>\n      <th>acq</th>\n      <td>2292</td>\n    </tr>\n    <tr>\n      <th>crude</th>\n      <td>374</td>\n    </tr>\n    <tr>\n      <th>trade</th>\n      <td>326</td>\n    </tr>\n    <tr>\n      <th>money-fx</th>\n      <td>293</td>\n    </tr>\n    <tr>\n      <th>interest</th>\n      <td>271</td>\n    </tr>\n    <tr>\n      <th>ship</th>\n      <td>144</td>\n    </tr>\n    <tr>\n      <th>grain</th>\n      <td>51</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------STARTING WITH R8----------------------------\n",
    "##------------BUILDING THE DATASET\n",
    "X_train = pd.read_csv('datasets/r8-train-all-terms.txt', sep=\"\\t\", header=None)\n",
    "X_test = pd.read_csv('datasets/r8-test-all-terms.txt', sep=\"\\t\", header=None)\n",
    "data_r8=pd.concat([X_train,X_test], ignore_index=True)\n",
    "data_r8.columns = [\"class\", \"text\"]\n",
    "classes_count = data_r8.groupby('class').count().sort_values(by=['text'],ascending=False)\n",
    "classes_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "##------------NLP PRE-PROCESSING START FROM HERE-------------##\n",
    "def nlp_preprocessing(text):\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n",
    "    # Replace nweline by some space\n",
    "    text = text.replace('\\r\\n', ' ').replace('\\n', ' ')\n",
    "    word_tokens = word_tokenize(text)  # n_rows 1971\n",
    "    stems = ''\n",
    "    for word in word_tokens:\n",
    "        stemed_word = stemmer.stem(word)\n",
    "        if ((stemed_word not in stopwords) and (re.search('[a-zA-Z]', stemed_word)) and stemed_word.isalpha() and len(stemed_word) > 3):\n",
    "            stems = stems + ' ' + stemed_word\n",
    "\n",
    "    return stems[1:]  # to remove the first space of the file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7673\r"
     ]
    }
   ],
   "source": [
    "data_r8_processed = data_r8\n",
    "for index ,row in data_r8_processed.iterrows():\n",
    "    print(index, end=\"\\r\")\n",
    "    row['text'] = nlp_preprocessing(row['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "1346"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp_preprocessing(data_r8.iloc[5][\"text\"]))\n",
    "len(data_r8.iloc[5][\"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853\n",
      "1346\n"
     ]
    }
   ],
   "source": [
    "print(len(data_r8_processed.iloc[5][\"text\"]))\n",
    "print(len(data_r8.iloc[5][\"text\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}