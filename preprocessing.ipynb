{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ast\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from keras.metrics import CosineSimilarity\n",
    "from nltk import word_tokenize\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "          text\nclass         \nearn      3923\nacq       2292\ncrude      374\ntrade      326\nmoney-fx   293\ninterest   271\nship       144\ngrain       51",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>class</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>earn</th>\n      <td>3923</td>\n    </tr>\n    <tr>\n      <th>acq</th>\n      <td>2292</td>\n    </tr>\n    <tr>\n      <th>crude</th>\n      <td>374</td>\n    </tr>\n    <tr>\n      <th>trade</th>\n      <td>326</td>\n    </tr>\n    <tr>\n      <th>money-fx</th>\n      <td>293</td>\n    </tr>\n    <tr>\n      <th>interest</th>\n      <td>271</td>\n    </tr>\n    <tr>\n      <th>ship</th>\n      <td>144</td>\n    </tr>\n    <tr>\n      <th>grain</th>\n      <td>51</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------STARTING WITH R8----------------------------\n",
    "##------------BUILDING THE DATASET\n",
    "X_train = pd.read_csv('datasets/r8-train-all-terms.txt', sep=\"\\t\", header=None)\n",
    "X_test = pd.read_csv('datasets/r8-test-all-terms.txt', sep=\"\\t\", header=None)\n",
    "data_r8=pd.concat([X_train,X_test], ignore_index=True)\n",
    "data_r8.columns = [\"class\", \"text\"]\n",
    "classes_count = data_r8.groupby('class').count().sort_values(by=['text'],ascending=False)\n",
    "classes_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#---------------STARTING WITH R52----------------------------\n",
    "##------------BUILDING THE DATASET\n",
    "X_train = pd.read_csv('datasets/r52-train-all-terms.txt', sep=\"\\t\", header=None)\n",
    "X_test = pd.read_csv('datasets/r52-test-all-terms.txt', sep=\"\\t\", header=None)\n",
    "data_r52=pd.concat([X_train,X_test], ignore_index=True)\n",
    "data_r52.columns = [\"class\", \"text\"]\n",
    "classes_count = data_r52.groupby('class').count().sort_values(by=['text'],ascending=False)\n",
    "classes_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#---------------STARTING WITH R52----------------------------\n",
    "##------------BUILDING THE DATASET\n",
    "X_train = pd.read_csv('datasets/r52-train-all-terms.txt', sep=\"\\t\", header=None)\n",
    "X_test = pd.read_csv('datasets/r52-test-all-terms.txt', sep=\"\\t\", header=None)\n",
    "data_r52=pd.concat([X_train,X_test], ignore_index=True)\n",
    "data_r52.columns = [\"class\", \"text\"]\n",
    "classes_count = data_r52.groupby('class').count().sort_values(by=['text'],ascending=False)\n",
    "classes_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "       text\nclass      \n3      3972\n4      2423\n19      682\n16      543\n1       537\n11      473\n20      339\n13      209\n8       177\n10      154\n21      127\n9       126\n25      123\n2        94\n18       86\n24       81\n0        67\n12       62\n6        62\n36       60\n28       58\n30       57\n34       57\n23       53\n31       52\n17       51\n40       46\n32       42\n41       38\n26       32\n39       29\n15       29\n14       28\n43       27\n29       23\n22       22\n5        22\n38       22\n37       21\n45       19\n7        19\n27       19\n44       17\n33       16\n42       16\n35       16",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>class</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>3972</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2423</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>682</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>543</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>537</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>473</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>339</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>209</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>177</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>154</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>127</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>126</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>123</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>94</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------STARTING WITH R40----------------------------\n",
    "##------------BUILDING THE DATASET\n",
    "X_train = pd.read_csv('datasets/r40_texts.txt', header=None)\n",
    "X_labels = pd.read_csv('datasets/r40_labels.txt', header=None)\n",
    "data_r40=pd.concat([X_labels, X_train], axis=1, ignore_index=True)\n",
    "data_r40.columns = [\"class\", \"text\"]\n",
    "classes_count = data_r40.groupby('class').count().sort_values(by=['text'],ascending=False)\n",
    "classes_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "       text\nclass      \ncacm   3204\ncisi   1460\ncran   1398\nmed    1033",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>class</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>cacm</th>\n      <td>3204</td>\n    </tr>\n    <tr>\n      <th>cisi</th>\n      <td>1460</td>\n    </tr>\n    <tr>\n      <th>cran</th>\n      <td>1398</td>\n    </tr>\n    <tr>\n      <th>med</th>\n      <td>1033</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------Dataset CLASSIC4----------------------------\n",
    "##------------BUILDING THE DATASET\n",
    "\n",
    "list_ = []\n",
    "with open(\"datasets/classic4.json\",'r+') as g:\n",
    "    for x in g:\n",
    "        list_.append(ast.literal_eval(x))\n",
    "\n",
    "classic4 = pd.DataFrame(list_)\n",
    "classic4.columns = [\"text\", \"class\"]\n",
    "classes_count = classic4.groupby('class').count().sort_values(by=['text'],ascending=False)\n",
    "classes_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#---------------Dataset CLASSIC3----------------------------\n",
    "##------------BUILDING THE DATASET\n",
    "\n",
    "list_ = []\n",
    "with open(\"datasets/classic3.json\",'r+') as g:\n",
    "    for x in g:\n",
    "        list_.append(ast.literal_eval(x))\n",
    "\n",
    "classic3 = pd.DataFrame(list_)\n",
    "classic3.columns = [\"text\", \"class\"]\n",
    "classes_count = classic3.groupby('class').count().sort_values(by=['text'],ascending=False)\n",
    "classes_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "         text\nclass        \nstudent  1625\nfaculty  1116\ncourse    926\nproject   501",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>class</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>student</th>\n      <td>1625</td>\n    </tr>\n    <tr>\n      <th>faculty</th>\n      <td>1116</td>\n    </tr>\n    <tr>\n      <th>course</th>\n      <td>926</td>\n    </tr>\n    <tr>\n      <th>project</th>\n      <td>501</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------DATASET WEBKB STEMMED----------------------------\n",
    "##------------BUILDING THE DATASET\n",
    "X_train = pd.read_csv('datasets/webkb-train-stemmed.txt', sep=\"\\t\", header=None)\n",
    "X_test = pd.read_csv('datasets/webkb-test-stemmed.txt', sep=\"\\t\", header=None)\n",
    "data_webkb = pd.concat([X_test, X_train], ignore_index=True)\n",
    "data_webkb.columns = [\"class\", \"text\"]\n",
    "classes_count = data_webkb.groupby('class').count().sort_values(by=['text'],ascending=False)\n",
    "classes_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 11314 into shape (1,0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-30-d998f13f067c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdatasets\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mfetch_20newsgroups\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mng20\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfetch_20newsgroups\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mdata_ng20\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mng20\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mlabels_ng20\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mng20\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: cannot reshape array of size 11314 into shape (1,0)"
     ]
    }
   ],
   "source": [
    "#---------------DATASET NG20----------------------------\n",
    "##------------BUILDING THE DATASET\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "ng20 = fetch_20newsgroups()\n",
    "data_ng20 = ng20.data\n",
    "labels_ng20 = ng20.target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('datasets/webkb-train-stemmed.txt', sep=\"\\t\", header=None)\n",
    "X_test = pd.read_csv('datasets/webkb-test-stemmed.txt', sep=\"\\t\", header=None)\n",
    "data_webkb = pd.concat([X_test, X_train], ignore_index=True)\n",
    "data_webkb.columns = [\"class\", \"text\"]\n",
    "classes_count = data_webkb.groupby('class').count().sort_values(by=['text'],ascending=False)\n",
    "classes_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##------------PRE-PROCESSING START FROM HERE-------------##\n",
    "def nlp_preprocessing(text):\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n",
    "    # Replace nweline by some space\n",
    "    text = text.replace('\\r\\n', ' ').replace('\\n', ' ')\n",
    "    word_tokens = word_tokenize(text)  # n_rows 1971\n",
    "    stems = ''\n",
    "    for word in word_tokens:\n",
    "        stemed_word = stemmer.stem(word)\n",
    "        if ((stemed_word not in stopwords) and (re.search('[a-zA-Z]', stemed_word)) and stemed_word.isalpha() and len(stemed_word) > 3):\n",
    "            stems = stems + ' ' + stemed_word\n",
    "\n",
    "    return stems[1:]  # to remove the first space of the file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7673\r"
     ]
    }
   ],
   "source": [
    "data_r8_processed = data_r8\n",
    "for index ,row in data_r8_processed.iterrows():\n",
    "    print(index, end=\"\\r\")\n",
    "    row['text'] = nlp_preprocessing(row['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "1346"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp_preprocessing(data_r8.iloc[5][\"text\"]))\n",
    "len(data_r8.iloc[5][\"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853\n",
      "1346\n"
     ]
    }
   ],
   "source": [
    "print(len(data_r8_processed.iloc[5][\"text\"]))\n",
    "print(len(data_r8.iloc[5][\"text\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "##------------CO-CLUSTERING START FROM HERE-------------##\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(np.unique(data_r8_processed['class']))\n",
    "data = data_r8_processed['text']\n",
    "labels = list(le.transform(data_r8_processed['class'].tolist()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from coclust.coclustering import CoclustInfo, CoclustMod, CoclustSpecMod\n",
    "from coclust.evaluation.external import accuracy\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "def execute_coclustering(tf_idf, method, n_clusters, return_pred_rows=True, max_iteration=300):\n",
    "    global model\n",
    "    print(\"---executing \",method)\n",
    "    if(method==\"CoclustInfo\"):\n",
    "        model = CoclustInfo(n_row_clusters=n_clusters, n_col_clusters=n_clusters, n_init=10, max_iter=max_iteration)\n",
    "    elif(method==\"CoclustMod\"):\n",
    "        model = CoclustMod(n_clusters=n_clusters, n_init=10, max_iter=max_iteration)\n",
    "    elif(method==\"CoclustModFuzzy\"):\n",
    "        model = CoclustSpecMod(n_clusters=n_clusters, n_init=10, max_iter=max_iteration)\n",
    "    model.fit(tf_idf)\n",
    "    pred_row_labels = model.row_labels_\n",
    "    pred_column_labels = model.column_labels_\n",
    "    if(return_pred_rows):\n",
    "        return  pred_row_labels\n",
    "    else:\n",
    "        return pred_column_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# Evaluate the results\n",
    "def clustering_quality(true_row_labels, predicted_row_labels):\n",
    "    nmi_ = nmi(true_row_labels, predicted_row_labels)\n",
    "    ari_ = ari(true_row_labels, predicted_row_labels)\n",
    "    acc_ = accuracy(true_row_labels, predicted_row_labels)\n",
    "    print(\"NMI : {}\\nARI : {}\\nAccuracy : {}\".format(nmi_, ari_, acc_))\n",
    "    return nmi_, ari_, acc_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "def execute_clustering_evaluation(raw_data, true_labels, row_labels=True,use_words_thresh=True, max_iteration=300):\n",
    "    global tfidf_vectorizer\n",
    "    clustering_eval = []\n",
    "    n_labels = len(np.unique(true_labels))\n",
    "    if(use_words_thresh):\n",
    "        tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_features=5000, max_df=0.7, min_df=0.001)\n",
    "    elif(not use_words_thresh):\n",
    "        tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_features=5000)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(raw_data)\n",
    "    colustering_methods = [\"CoclustInfo\", \"CoclustMod\", \"CoclustModFuzzy\"]\n",
    "    for algo in colustering_methods:\n",
    "        pred_labels = execute_coclustering(tfidf_matrix, algo, n_labels, return_pred_rows=row_labels, max_iteration=max_iteration)\n",
    "        nmi_, ari_, acc_ = clustering_quality(true_labels, pred_labels)\n",
    "        clustering_eval += [[algo, nmi_, ari_, acc_]]\n",
    "    return clustering_eval"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---executing  CoclustInfo\n",
      "NMI : 0.4173487731492575\n",
      "ARI : 0.2573006538465157\n",
      "Accuracy : 0.40474328902788637\n",
      "---executing  CoclustMod\n",
      "NMI : 0.4226733813737461\n",
      "ARI : 0.318515137141091\n",
      "Accuracy : 0.4756320041699244\n",
      "---executing  CoclustModFuzzy\n",
      "NMI : 0.47719071468224405\n",
      "ARI : 0.34927249797899385\n",
      "Accuracy : 0.6215793588741204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedali/anaconda3/lib/python3.7/site-packages/coclust/coclustering/coclust_info.py:97: FutureWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  warn_on_dtype=False, estimator=None)\n",
      "/home/mohamedali/anaconda3/lib/python3.7/site-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n",
      "/home/mohamedali/anaconda3/lib/python3.7/site-packages/coclust/coclustering/coclust_mod.py:97: FutureWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  warn_on_dtype=False, estimator=None)\n",
      "/home/mohamedali/anaconda3/lib/python3.7/site-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n",
      "/home/mohamedali/anaconda3/lib/python3.7/site-packages/coclust/coclustering/coclust_spec_mod.py:87: FutureWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  warn_on_dtype=False, estimator=None)\n",
      "/home/mohamedali/anaconda3/lib/python3.7/site-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "evaluation_list = execute_clustering_evaluation(data, labels, use_words_thresh=True, max_iteration=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "evaluation_df = pd.DataFrame(evaluation_list, columns=[ \"method\", \"nmi\", \"ari\", \"acc\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_features=5000, max_df=0.7, min_df=0.001)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "documents1 = tfidf_matrix[0].todense())\n",
    "documents2 = list(tfidf_matrix[1].todense())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m     91\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 92\u001B[0;31m       \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_datatype_enum\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     93\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'as_datatype_enum'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-104-9293217a9e03>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mCosineSimilarity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdocuments1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdocuments2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/keras/metrics.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, dtype, axis)\u001B[0m\n\u001B[1;32m    701\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'cosine_similarity'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    702\u001B[0m         super(CosineSimilarity, self).__init__(\n\u001B[0;32m--> 703\u001B[0;31m             cosine_similarity, name, dtype=dtype, axis=axis)\n\u001B[0m\u001B[1;32m    704\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    705\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/keras/metrics.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, fn, name, dtype, **kwargs)\u001B[0m\n\u001B[1;32m    293\u001B[0m             \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mThe\u001B[0m \u001B[0mkeyword\u001B[0m \u001B[0marguments\u001B[0m \u001B[0mthat\u001B[0m \u001B[0mare\u001B[0m \u001B[0mpassed\u001B[0m \u001B[0mon\u001B[0m \u001B[0mto\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    294\u001B[0m         \"\"\"\n\u001B[0;32m--> 295\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mMeanMetricWrapper\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    296\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    297\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fn_kwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/keras/metrics.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, dtype)\u001B[0m\n\u001B[1;32m    277\u001B[0m         \"\"\"\n\u001B[1;32m    278\u001B[0m         super(Mean, self).__init__(\n\u001B[0;32m--> 279\u001B[0;31m             reduction=metrics_utils.Reduction.WEIGHTED_MEAN, name=name, dtype=dtype)\n\u001B[0m\u001B[1;32m    280\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/keras/metrics.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, reduction, name, dtype)\u001B[0m\n\u001B[1;32m    150\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreduction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreduction\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    151\u001B[0m         self.total = self.add_weight(\n\u001B[0;32m--> 152\u001B[0;31m             'total', initializer='zeros')\n\u001B[0m\u001B[1;32m    153\u001B[0m         if reduction in [metrics_utils.Reduction.SUM_OVER_BATCH_SIZE,\n\u001B[1;32m    154\u001B[0m                          metrics_utils.Reduction.WEIGHTED_MEAN]:\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/keras/metrics.py\u001B[0m in \u001B[0;36madd_weight\u001B[0;34m(self, name, shape, initializer, dtype)\u001B[0m\n\u001B[1;32m    131\u001B[0m             \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mdtype\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    132\u001B[0m             \u001B[0mtrainable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 133\u001B[0;31m             initializer=initializer)\n\u001B[0m\u001B[1;32m    134\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    135\u001B[0m     \u001B[0;31m# End: For use by subclasses ###\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36madd_weight\u001B[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001B[0m\n\u001B[1;32m    277\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mdtype\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    278\u001B[0m             \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 279\u001B[0;31m         weight = K.variable(initializer(shape, dtype=dtype),\n\u001B[0m\u001B[1;32m    280\u001B[0m                             \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    281\u001B[0m                             \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/keras/initializers.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, shape, dtype)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mK\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconstant\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001B[0m in \u001B[0;36mconstant\u001B[0;34m(value, dtype, shape, name)\u001B[0m\n\u001B[1;32m    647\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtf_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minit_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    648\u001B[0m         return tf_keras_backend.constant(\n\u001B[0;32m--> 649\u001B[0;31m             value, dtype=dtype, shape=shape, name=name)\n\u001B[0m\u001B[1;32m    650\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    651\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001B[0m in \u001B[0;36mconstant\u001B[0;34m(value, dtype, shape, name)\u001B[0m\n\u001B[1;32m    932\u001B[0m     \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfloatx\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    933\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 934\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mconstant_op\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconstant\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    935\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    936\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconstant\u001B[0;34m(value, dtype, shape, name)\u001B[0m\n\u001B[1;32m    225\u001B[0m   \"\"\"\n\u001B[1;32m    226\u001B[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001B[0;32m--> 227\u001B[0;31m                         allow_broadcast=True)\n\u001B[0m\u001B[1;32m    228\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    229\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_impl\u001B[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001B[0m\n\u001B[1;32m    233\u001B[0m   \u001B[0mctx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    234\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 235\u001B[0;31m     \u001B[0mt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_to_eager_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    236\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mshape\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    237\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m     92\u001B[0m       \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_datatype_enum\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     93\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 94\u001B[0;31m       \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_datatype_enum\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     95\u001B[0m   \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     96\u001B[0m   \u001B[0;32mreturn\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEagerTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/dtypes.py\u001B[0m in \u001B[0;36mas_dtype\u001B[0;34m(type_value)\u001B[0m\n\u001B[1;32m    714\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    715\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 716\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_ANY_TO_TF\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype_value\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    717\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    718\u001B[0m     \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "CosineSimilarity(documents1,documents2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 2947)"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}