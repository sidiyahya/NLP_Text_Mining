{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "          text\nclass         \nearn      3923\nacq       2292\ncrude      374\ntrade      326\nmoney-fx   293\ninterest   271\nship       144\ngrain       51",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>class</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>earn</th>\n      <td>3923</td>\n    </tr>\n    <tr>\n      <th>acq</th>\n      <td>2292</td>\n    </tr>\n    <tr>\n      <th>crude</th>\n      <td>374</td>\n    </tr>\n    <tr>\n      <th>trade</th>\n      <td>326</td>\n    </tr>\n    <tr>\n      <th>money-fx</th>\n      <td>293</td>\n    </tr>\n    <tr>\n      <th>interest</th>\n      <td>271</td>\n    </tr>\n    <tr>\n      <th>ship</th>\n      <td>144</td>\n    </tr>\n    <tr>\n      <th>grain</th>\n      <td>51</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------STARTING WITH R8----------------------------\n",
    "##------------BUILDING THE DATASET\n",
    "X_train = pd.read_csv('datasets/r8-train-all-terms.txt', sep=\"\\t\", header=None)\n",
    "X_test = pd.read_csv('datasets/r8-test-all-terms.txt', sep=\"\\t\", header=None)\n",
    "data_r8=pd.concat([X_train,X_test], ignore_index=True)\n",
    "data_r8.columns = [\"class\", \"text\"]\n",
    "classes_count = data_r8.groupby('class').count().sort_values(by=['text'],ascending=False)\n",
    "classes_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "##------------PRE-PROCESSING START FROM HERE-------------##\n",
    "def nlp_preprocessing(text):\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n",
    "    # Replace nweline by some space\n",
    "    text = text.replace('\\r\\n', ' ').replace('\\n', ' ')\n",
    "    word_tokens = word_tokenize(text)  # n_rows 1971\n",
    "    stems = ''\n",
    "    for word in word_tokens:\n",
    "        stemed_word = stemmer.stem(word)\n",
    "        if ((stemed_word not in stopwords) and (re.search('[a-zA-Z]', stemed_word)) and stemed_word.isalpha() and len(stemed_word) > 3):\n",
    "            stems = stems + ' ' + stemed_word\n",
    "\n",
    "    return stems[1:]  # to remove the first space of the file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7673\r"
     ]
    }
   ],
   "source": [
    "data_r8_processed = data_r8\n",
    "for index ,row in data_r8_processed.iterrows():\n",
    "    print(index, end=\"\\r\")\n",
    "    row['text'] = nlp_preprocessing(row['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "1346"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp_preprocessing(data_r8.iloc[5][\"text\"]))\n",
    "len(data_r8.iloc[5][\"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853\n",
      "1346\n"
     ]
    }
   ],
   "source": [
    "print(len(data_r8_processed.iloc[5][\"text\"]))\n",
    "print(len(data_r8.iloc[5][\"text\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "##------------CO-CLUSTERING START FROM HERE-------------##\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(np.unique(data_r8_processed['class']))\n",
    "data = data_r8_processed['text']\n",
    "labels = list(le.transform(data_r8_processed['class'].tolist()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from coclust.coclustering import CoclustInfo, CoclustMod, CoclustSpecMod\n",
    "from coclust.evaluation.external import accuracy\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "def execute_coclustering(tf_idf, method, n_clusters, return_pred_rows=True, max_iteration=300):\n",
    "    global model\n",
    "    print(\"---executing \",method)\n",
    "    if(method==\"CoclustInfo\"):\n",
    "        model = CoclustInfo(n_row_clusters=n_clusters, n_col_clusters=n_clusters, n_init=10, max_iter=max_iteration)\n",
    "    elif(method==\"CoclustMod\"):\n",
    "        model = CoclustMod(n_clusters=n_clusters, n_init=10, max_iter=max_iteration)\n",
    "    elif(method==\"CoclustModFuzzy\"):\n",
    "        model = CoclustSpecMod(n_clusters=n_clusters, n_init=10, max_iter=max_iteration)\n",
    "    model.fit(tf_idf)\n",
    "    pred_row_labels = model.row_labels_\n",
    "    pred_column_labels = model.column_labels_\n",
    "    if(return_pred_rows):\n",
    "        return  pred_row_labels\n",
    "    else:\n",
    "        return pred_column_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# Evaluate the results\n",
    "def clustering_quality(true_row_labels, predicted_row_labels):\n",
    "    nmi_ = nmi(true_row_labels, predicted_row_labels)\n",
    "    ari_ = ari(true_row_labels, predicted_row_labels)\n",
    "    acc_ = accuracy(true_row_labels, predicted_row_labels)\n",
    "    print(\"NMI : {}\\nARI : {}\\nAccuracy : {}\".format(nmi_, ari_, acc_))\n",
    "    return nmi_, ari_, acc_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "def execute_clustering_evaluation(raw_data, true_labels, row_labels=True,use_words_thresh=True, max_iteration=300):\n",
    "    global tfidf_vectorizer\n",
    "    clustering_eval = []\n",
    "    n_labels = len(np.unique(true_labels))\n",
    "    if(use_words_thresh):\n",
    "        tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_features=5000, max_df=0.7, min_df=0.001)\n",
    "    elif(not use_words_thresh):\n",
    "        tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_features=5000)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(raw_data)\n",
    "    colustering_methods = [\"CoclustInfo\", \"CoclustMod\", \"CoclustModFuzzy\"]\n",
    "    for algo in colustering_methods:\n",
    "        pred_labels = execute_coclustering(tfidf_matrix, algo, n_labels, return_pred_rows=row_labels, max_iteration=max_iteration)\n",
    "        nmi_, ari_, acc_ = clustering_quality(true_labels, pred_labels)\n",
    "        clustering_eval += [[algo, nmi_, ari_, acc_]]\n",
    "    return clustering_eval"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---executing  CoclustInfo\n",
      "NMI : 0.4173487731492575\n",
      "ARI : 0.2573006538465157\n",
      "Accuracy : 0.40474328902788637\n",
      "---executing  CoclustMod\n",
      "NMI : 0.4226733813737461\n",
      "ARI : 0.318515137141091\n",
      "Accuracy : 0.4756320041699244\n",
      "---executing  CoclustModFuzzy\n",
      "NMI : 0.47719071468224405\n",
      "ARI : 0.34927249797899385\n",
      "Accuracy : 0.6215793588741204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedali/anaconda3/lib/python3.7/site-packages/coclust/coclustering/coclust_info.py:97: FutureWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  warn_on_dtype=False, estimator=None)\n",
      "/home/mohamedali/anaconda3/lib/python3.7/site-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n",
      "/home/mohamedali/anaconda3/lib/python3.7/site-packages/coclust/coclustering/coclust_mod.py:97: FutureWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  warn_on_dtype=False, estimator=None)\n",
      "/home/mohamedali/anaconda3/lib/python3.7/site-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n",
      "/home/mohamedali/anaconda3/lib/python3.7/site-packages/coclust/coclustering/coclust_spec_mod.py:87: FutureWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  warn_on_dtype=False, estimator=None)\n",
      "/home/mohamedali/anaconda3/lib/python3.7/site-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "evaluation_list = execute_clustering_evaluation(data, labels, use_words_thresh=True, max_iteration=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "evaluation_df = pd.DataFrame(evaluation_list, columns=[ \"method\", \"nmi\", \"ari\", \"acc\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}